{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5815d651",
   "metadata": {},
   "source": [
    "### DESCRIPTION\n",
    "---\n",
    "\n",
    "Using NLP and machine learning, make a model to identify toxic comments from the Talk edit pages on Wikipedia. Help identify the words that make a comment toxic.\n",
    "\n",
    "#### Problem Statement:  \n",
    "---\n",
    "Wikipedia is the world’s largest and most popular reference work on the internet with about 500 million unique visitors per month. It also has millions of contributors who can make edits to pages. The Talk edit pages, the key community interaction forum where the contributing community interacts or discusses or debates about the changes pertaining to a particular topic. \n",
    "\n",
    "Wikipedia continuously strives to help online discussion become more productive and respectful. You are a data scientist at Wikipedia who will help Wikipedia to build a predictive model that identifies toxic comments in the discussion and marks them for cleanup by using NLP and machine learning. Post that, help identify the top terms from the toxic comments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b922d3d",
   "metadata": {},
   "source": [
    "### Tasks: \n",
    "\n",
    "<i> 1. Load the data using read_csv function from pandas package <br>\n",
    "2. Get the comments into a list, for easy text cleanup and manipulation <br>\n",
    "3. Cleanup:\n",
    "- Using regular expressions, remove IP addresses <br>\n",
    "- Using regular expressions, remove URLs <br>\n",
    "- Normalize the casing <br>\n",
    "- Tokenize using word_tokenize from NLTK <br>\n",
    "- Remove stop words <br>\n",
    "- Remove punctuation <br>\n",
    "- Define a function to perform all these steps, you’ll use this later on the actual test set <br> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56fc19b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calling required libraries..\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, RegexpStemmer,SnowballStemmer,WordNetLemmatizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.chunk import ne_chunk\n",
    "from nltk.corpus import brown\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import spacy\n",
    "import string as str\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.metrics.distance import jaccard_distance\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import words\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "from spellchecker import SpellChecker\n",
    "PS = PorterStemmer()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import mean_squared_error,mean_squared_log_error,r2_score,classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "from collections import  Counter\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "103fc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_Toxicity = pd.read_csv('C:/Working Files/Mac ka folder/Simplilearn/NLP/Online Classes/Wikipedia Toxicity/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27e4f1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            5000 non-null   object\n",
      " 1   comment_text  5000 non-null   object\n",
      " 2   toxic         5000 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 117.3+ KB\n"
     ]
    }
   ],
   "source": [
    "Wikipedia_Toxicity.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09422921",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4563\n",
       "1     437\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikipedia_Toxicity[\"toxic\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51632f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    phrase = re.sub(r\"don\\'t\", \" do not\", phrase)\n",
    "    phrase = re.sub(r\"doesn\\'t\", \" does not\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa2e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "my_stopwords = stopwords.words(\"english\")\n",
    "def textPreprocessing(document):\n",
    "    document = decontracted(document)\n",
    "    #0.Remove IP Address\n",
    "    withoutIPaddress = re.sub(r\"\\d{1,3}.\\d{1,3}.\\d{1,3}.\\d{1,3}\", \"\", document)\n",
    "    #0.Remove IP URL\n",
    "    withouturladdress = re.sub(r'\\w+:\\/{2}[\\d\\w-]+(\\.[\\d\\w-]+)*(?:(?:\\/[^\\s/]*))*',\"\",withoutIPaddress)\n",
    "    #1. Remove Punctuations\n",
    "    sentWithoutPunct = ''.join([char for char in withouturladdress  if char not in str.punctuation]) \n",
    "    #2. Extract words out of the sentences\n",
    "    words = sentWithoutPunct.split()\n",
    "    #3. Normalize the data (lowercase)\n",
    "    wordNormalized = [word.lower() for word in words]\n",
    "    # 4. Remove Stopwords\n",
    "    vocabulary = [word for word in wordNormalized if word not in my_stopwords]\n",
    "    sent = ' '.join(vocabulary)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e95ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_Toxicity [\"cleaned_comment\"] = Wikipedia_Toxicity[\"comment_text\"].apply(textPreprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d32112e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>cleaned_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n",
       "      <td>0</td>\n",
       "      <td>barnstar defender wiki barnstar like edit kaya...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>seems unbalanced whatever said mathsci said fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n",
       "      <td>0</td>\n",
       "      <td>marya dzmitruk born minsk belarus march 19 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>talkback dear celestia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n",
       "      <td>0</td>\n",
       "      <td>new categories honestly think need add categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>60229df7b48ba6ff</td>\n",
       "      <td>\"\\r\\n\\r\\n Dildo, if you read my response corre...</td>\n",
       "      <td>0</td>\n",
       "      <td>dildo read response correctly never said going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>36a645227572ec5c</td>\n",
       "      <td>CALM DOWN, CALM DOWN, DON'T GET A BIG DICK</td>\n",
       "      <td>1</td>\n",
       "      <td>calm calm dont get big dick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>6d47fa39945ed6f5</td>\n",
       "      <td>In my opinion Dougweller is using his privileg...</td>\n",
       "      <td>0</td>\n",
       "      <td>opinion dougweller using privileges poorly per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>de2e4c0d38db6e30</td>\n",
       "      <td>The style section has been expanded too. I did...</td>\n",
       "      <td>0</td>\n",
       "      <td>style section expanded remember placed tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4cda24210a33ac35</td>\n",
       "      <td>ANY ONE THAT IS NOT AGREEMENT WITH YOU OR IS A...</td>\n",
       "      <td>0</td>\n",
       "      <td>one agreement repulican joe hazelton wack mole...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                       comment_text  \\\n",
       "0     e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...   \n",
       "1     9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...   \n",
       "2     ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...   \n",
       "3     48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"   \n",
       "4     0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...   \n",
       "...                ...                                                ...   \n",
       "4995  60229df7b48ba6ff  \"\\r\\n\\r\\n Dildo, if you read my response corre...   \n",
       "4996  36a645227572ec5c         CALM DOWN, CALM DOWN, DON'T GET A BIG DICK   \n",
       "4997  6d47fa39945ed6f5  In my opinion Dougweller is using his privileg...   \n",
       "4998  de2e4c0d38db6e30  The style section has been expanded too. I did...   \n",
       "4999  4cda24210a33ac35  ANY ONE THAT IS NOT AGREEMENT WITH YOU OR IS A...   \n",
       "\n",
       "      toxic                                    cleaned_comment  \n",
       "0         0  barnstar defender wiki barnstar like edit kaya...  \n",
       "1         0  seems unbalanced whatever said mathsci said fa...  \n",
       "2         0  marya dzmitruk born minsk belarus march 19 199...  \n",
       "3         0                             talkback dear celestia  \n",
       "4         0  new categories honestly think need add categor...  \n",
       "...     ...                                                ...  \n",
       "4995      0  dildo read response correctly never said going...  \n",
       "4996      1                        calm calm dont get big dick  \n",
       "4997      0  opinion dougweller using privileges poorly per...  \n",
       "4998      0         style section expanded remember placed tag  \n",
       "4999      0  one agreement repulican joe hazelton wack mole...  \n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikipedia_Toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c5b30",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i> 4. Using a counter, find the top terms in the data:\n",
    " - Can any of these be considered contextual stop words? <br> \n",
    " - Words like “Wikipedia”, “page”, “edit” are examples of contextual stop words <br>\n",
    " - If yes, drop these from the data <br> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e899f5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_non_stopwords(text):\n",
    "    stop=set(stopwords.words('english'))\n",
    "    \n",
    "    new= text.str.split()\n",
    "    new=new.values.tolist()\n",
    "    corpus=[word for i in new for word in i]\n",
    "\n",
    "    counter=Counter(corpus)\n",
    "    most=counter.most_common()\n",
    "    x, y=[], []\n",
    "    for word,count in most[:300]:\n",
    "        if (word not in stop):\n",
    "            x.append(word)\n",
    "            y.append(count)\n",
    "            \n",
    "    return pd.DataFrame(x,y,columns=[\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a2f4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_300_words = top_non_stopwords(Wikipedia_Toxicity[\"cleaned_comment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8ec21c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>changes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>facts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>word</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>mentioned</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>message</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>reverted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>following</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>consider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>book</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>whether</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>perhaps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>regarding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>eat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>date</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>simply</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>state</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>proassadhanibal911you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>research</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>statement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>times</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>else</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>account</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>called</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>listed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>less</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>based</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>maybe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>dont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>seem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>notice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>position</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>idea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>revert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>makes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>appropriate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>website</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>course</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>community</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>whole</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      word\n",
       "110                changes\n",
       "110                  facts\n",
       "110                    day\n",
       "110                   word\n",
       "109                   life\n",
       "109              mentioned\n",
       "108                message\n",
       "108               reverted\n",
       "108              following\n",
       "108               consider\n",
       "108                version\n",
       "107                   book\n",
       "107                whether\n",
       "106                perhaps\n",
       "106              regarding\n",
       "106                    eat\n",
       "106                   date\n",
       "106                 simply\n",
       "106                  state\n",
       "106  proassadhanibal911you\n",
       "105               research\n",
       "105              statement\n",
       "105                  times\n",
       "105                   else\n",
       "104                account\n",
       "104                 called\n",
       "104                 listed\n",
       "104                   less\n",
       "103                  group\n",
       "102                  based\n",
       "101                 review\n",
       "101                  maybe\n",
       "101                   tell\n",
       "101                   dont\n",
       "100                mention\n",
       "100                   seem\n",
       "99                  notice\n",
       "99                 correct\n",
       "99                position\n",
       "99                    idea\n",
       "98                  revert\n",
       "98                   makes\n",
       "98             appropriate\n",
       "97                     bad\n",
       "97                 website\n",
       "96                  course\n",
       "96                 general\n",
       "96               community\n",
       "96                   whole"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_300_words.iloc[251:300,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500dd90",
   "metadata": {},
   "source": [
    "#### The definition of contextual is depending on the context, or surrounding words, phrases, and paragraphs, of the writing. Following context words are dropped from cleaned_comment. As they don't directly represents context of statement.\n",
    "pages, page, wikipedia, wiki, encyclopedia, articles, article, sources, source, discussion, ytmndin, •, —,version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "27ec7b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_word = (\"pages page wikipedia wiki encyclopedia articles article artricle sources source discussion ytmndin • — version\").split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87086ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_without_context_word(document):\n",
    "    words = document.split()\n",
    "    vocabulary = [word for word in words if word not in context_word]\n",
    "    sent = ' '.join(vocabulary)\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d4429e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker(distance=1)\n",
    "def Correct(x):\n",
    "    return spell.correction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9a564a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_Toxicity[\"cleaned_comment_final\"] = Wikipedia_Toxicity[\"cleaned_comment\"].apply(document_without_context_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50a224a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Wikipedia_Toxicity[\"cleaned_comment_final\"] = Wikipedia_Toxicity[\"cleaned_comment_final\"].apply(Correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bb3ae6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>cleaned_comment_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e617e2489abe9bca</td>\n",
       "      <td>\"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...</td>\n",
       "      <td>0</td>\n",
       "      <td>barnstar defender wiki barnstar like edit kaya...</td>\n",
       "      <td>barnstar defender barnstar like edit kayastha ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9250cf637294e09d</td>\n",
       "      <td>\"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...</td>\n",
       "      <td>0</td>\n",
       "      <td>seems unbalanced whatever said mathsci said fa...</td>\n",
       "      <td>seems unbalanced whatever said mathsci said fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ce1aa4592d5240ca</td>\n",
       "      <td>Marya Dzmitruk was born in Minsk, Belarus in M...</td>\n",
       "      <td>0</td>\n",
       "      <td>marya dzmitruk born minsk belarus march 19 199...</td>\n",
       "      <td>marya dzmitruk born minsk belarus march 19 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48105766ff7f075b</td>\n",
       "      <td>\"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>talkback dear celestia</td>\n",
       "      <td>talkback dear celestia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0543d4f82e5470b6</td>\n",
       "      <td>New Categories \\r\\n\\r\\nI honestly think that w...</td>\n",
       "      <td>0</td>\n",
       "      <td>new categories honestly think need add categor...</td>\n",
       "      <td>new categories honestly think need add categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>60229df7b48ba6ff</td>\n",
       "      <td>\"\\r\\n\\r\\n Dildo, if you read my response corre...</td>\n",
       "      <td>0</td>\n",
       "      <td>dildo read response correctly never said going...</td>\n",
       "      <td>dildo read response correctly never said going...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>36a645227572ec5c</td>\n",
       "      <td>CALM DOWN, CALM DOWN, DON'T GET A BIG DICK</td>\n",
       "      <td>1</td>\n",
       "      <td>calm calm dont get big dick</td>\n",
       "      <td>calm calm dont get big dick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>6d47fa39945ed6f5</td>\n",
       "      <td>In my opinion Dougweller is using his privileg...</td>\n",
       "      <td>0</td>\n",
       "      <td>opinion dougweller using privileges poorly per...</td>\n",
       "      <td>opinion dougweller using privileges poorly per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>de2e4c0d38db6e30</td>\n",
       "      <td>The style section has been expanded too. I did...</td>\n",
       "      <td>0</td>\n",
       "      <td>style section expanded remember placed tag</td>\n",
       "      <td>style section expanded remember placed tag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4cda24210a33ac35</td>\n",
       "      <td>ANY ONE THAT IS NOT AGREEMENT WITH YOU OR IS A...</td>\n",
       "      <td>0</td>\n",
       "      <td>one agreement repulican joe hazelton wack mole...</td>\n",
       "      <td>one agreement repulican joe hazelton wack mole...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                       comment_text  \\\n",
       "0     e617e2489abe9bca  \"\\r\\n\\r\\n A barnstar for you! \\r\\n\\r\\n  The De...   \n",
       "1     9250cf637294e09d  \"\\r\\n\\r\\nThis seems unbalanced.  whatever I ha...   \n",
       "2     ce1aa4592d5240ca  Marya Dzmitruk was born in Minsk, Belarus in M...   \n",
       "3     48105766ff7f075b      \"\\r\\n\\r\\nTalkback\\r\\n\\r\\n Dear Celestia...  \"   \n",
       "4     0543d4f82e5470b6  New Categories \\r\\n\\r\\nI honestly think that w...   \n",
       "...                ...                                                ...   \n",
       "4995  60229df7b48ba6ff  \"\\r\\n\\r\\n Dildo, if you read my response corre...   \n",
       "4996  36a645227572ec5c         CALM DOWN, CALM DOWN, DON'T GET A BIG DICK   \n",
       "4997  6d47fa39945ed6f5  In my opinion Dougweller is using his privileg...   \n",
       "4998  de2e4c0d38db6e30  The style section has been expanded too. I did...   \n",
       "4999  4cda24210a33ac35  ANY ONE THAT IS NOT AGREEMENT WITH YOU OR IS A...   \n",
       "\n",
       "      toxic                                    cleaned_comment  \\\n",
       "0         0  barnstar defender wiki barnstar like edit kaya...   \n",
       "1         0  seems unbalanced whatever said mathsci said fa...   \n",
       "2         0  marya dzmitruk born minsk belarus march 19 199...   \n",
       "3         0                             talkback dear celestia   \n",
       "4         0  new categories honestly think need add categor...   \n",
       "...     ...                                                ...   \n",
       "4995      0  dildo read response correctly never said going...   \n",
       "4996      1                        calm calm dont get big dick   \n",
       "4997      0  opinion dougweller using privileges poorly per...   \n",
       "4998      0         style section expanded remember placed tag   \n",
       "4999      0  one agreement repulican joe hazelton wack mole...   \n",
       "\n",
       "                                  cleaned_comment_final  \n",
       "0     barnstar defender barnstar like edit kayastha ...  \n",
       "1     seems unbalanced whatever said mathsci said fa...  \n",
       "2     marya dzmitruk born minsk belarus march 19 199...  \n",
       "3                                talkback dear celestia  \n",
       "4     new categories honestly think need add categor...  \n",
       "...                                                 ...  \n",
       "4995  dildo read response correctly never said going...  \n",
       "4996                        calm calm dont get big dick  \n",
       "4997  opinion dougweller using privileges poorly per...  \n",
       "4998         style section expanded remember placed tag  \n",
       "4999  one agreement repulican joe hazelton wack mole...  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Wikipedia_Toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc4d26e",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i> 5. Separate into train and test sets\n",
    " - Use train-test method to divide your data into 2 sets: train and test <br>\n",
    " - Use a 70-30 split <br></i>\n",
    " \n",
    "<i> 6. Use TF-IDF values for the terms as feature to get into a vector space model\n",
    " - Import TF-IDF vectorizer from sklearn <br>\n",
    " - Instantiate with a maximum of 4000 terms in your vocabulary <br>\n",
    " - Fit and apply on the train set <br>\n",
    " - Apply on the test set <br> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8921452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Features = Wikipedia_Toxicity[\"cleaned_comment_final\"]\n",
    "Label = Wikipedia_Toxicity[\"toxic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38061f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features >> (5000,) Label >> (5000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Features >>\", Features.shape, \"Label >>\", Label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "66f1de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer =  TfidfVectorizer(max_features=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3468e9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(Features,Label,test_size=0.30,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66775f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train = vectorizer.fit_transform(X_train).toarray()\n",
    "tf_idf_test = vectorizer.fit_transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d592fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train >> (3500, 4000) Test >> (1500, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train >>\", tf_idf_train.shape, \"Test >>\", tf_idf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0cc1627",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i> 7. Model building: Support Vector Machine\n",
    " - Instantiate SVC from sklearn with a linear kernel <br>\n",
    " - Fit on the train data <br>\n",
    " - Make predictions for the train and the test set <br> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60c40c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1733b51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = SVC(C=1.0, kernel='linear', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2582eb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC.fit(tf_idf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8fdca641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is  0.97\n",
      "Testing score is  0.91\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score is \",round(SVC.score(tf_idf_train,y_train),2))\n",
    "print(\"Testing score is \",round(SVC.score(tf_idf_test,y_test),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac123b21",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i> 8. Model evaluation: Accuracy, recall, and f1_score\n",
    " - Report the accuracy on the train set <br>\n",
    " - Report the recall on the train set:decent, high, low? <br>\n",
    " - Get the f1_score on the train set <br> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de4a3278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.97      1.00      0.98      3186\n",
      "       Toxic       0.99      0.64      0.78       314\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.98      0.82      0.88      3500\n",
      "weighted avg       0.97      0.97      0.96      3500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train,SVC.predict(tf_idf_train),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401627c9",
   "metadata": {},
   "source": [
    "### Train data evaluation\n",
    "---\n",
    "precision is high for both Non-Toxic and Toxic. <br>\n",
    "f1 score is high for predicting Non-Toxic comments, comparatively low for Toxic comments. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d4abb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.92      0.99      0.95      1377\n",
      "       Toxic       0.00      0.00      0.00       123\n",
      "\n",
      "    accuracy                           0.91      1500\n",
      "   macro avg       0.46      0.49      0.48      1500\n",
      "weighted avg       0.84      0.91      0.87      1500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,SVC.predict(tf_idf_test),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8017b",
   "metadata": {},
   "source": [
    "### Test data evaluation\n",
    "---\n",
    "model failed to predict Toxic comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "865d2a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_features = vectorizer.fit_transform(Features).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d8c73a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.91      0.99      0.95      4563\n",
      "       Toxic       0.10      0.01      0.02       437\n",
      "\n",
      "    accuracy                           0.90      5000\n",
      "   macro avg       0.51      0.50      0.49      5000\n",
      "weighted avg       0.84      0.90      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Label,SVC.predict(tf_idf_features),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3b9499",
   "metadata": {},
   "source": [
    "### Overall Data evaluation\n",
    "---\n",
    "Model fully baised for Non-Toxic data..\n",
    "\n",
    "1. One approach to addressing imbalanced datasets is to adjust the parameters gamma='scale', class_weight='balanced' in the SVC module\n",
    "\n",
    "2. Second approach to addressing imbalanced datasets is to oversample the minority class, in this case Toxic data set. This type of data augmentation for the minority class is referred to as the Synthetic Minority Oversampling Technique, or SMOTE for short."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c00148",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i> 9. Looks like you need to adjust  the class imbalance, as the model seems to focus on the 0s\n",
    " - Adjust the appropriate parameter in the SVC module </i>\n",
    " \n",
    "<i> 10. Train again with the adjustment and evaluate\n",
    " - Train the model on the train set <br>\n",
    " - Evaluate the predictions on the validation set: accuracy, recall, f1_score <br> </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc22ee06",
   "metadata": {},
   "source": [
    "### Approach1: Adjust the parameters\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6e2c73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold,StratifiedKFold\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c7025a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {0:1.0, 1:85.0}\n",
    "SVC1 = SVC(class_weight=weights,kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbbdfb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight={0: 1.0, 1: 85.0}, kernel='linear')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC1.fit(tf_idf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7e2686f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is  0.97\n",
      "Testing score is  0.59\n",
      "--------------------------------------------------\n",
      "Training Data Statistics\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       1.00      0.97      0.99      3186\n",
      "       Toxic       0.78      1.00      0.88       314\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.89      0.99      0.93      3500\n",
      "weighted avg       0.98      0.97      0.98      3500\n",
      "\n",
      "--------------------------------------------------\n",
      "Overall Data Statistics\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.94      0.65      0.77      4563\n",
      "       Toxic       0.13      0.54      0.21       437\n",
      "\n",
      "    accuracy                           0.64      5000\n",
      "   macro avg       0.53      0.60      0.49      5000\n",
      "weighted avg       0.87      0.64      0.72      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score is \",round(SVC1.score(tf_idf_train,y_train),2))\n",
    "print(\"Testing score is \",round(SVC1.score(tf_idf_test,y_test),2))\n",
    "print(\"-\"*50)\n",
    "print(\"Training Data Statistics\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(y_train,SVC1.predict(tf_idf_train),target_names=[\"Non-Toxic\",\"Toxic\"]))\n",
    "print(\"-\"*50)\n",
    "print(\"Overall Data Statistics\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(Label,SVC1.predict(tf_idf_features),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fdc71e",
   "metadata": {},
   "source": [
    "We will replace weights = {0:1.0, 1:85.0} with 'balanced' pre-defined function with SVC to manage to manage imbalance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d697331a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC2 = SVC(class_weight='balanced',kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a7bc635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC2.fit(tf_idf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6a4b3fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is  0.98\n",
      "Testing score is  0.85\n",
      "--------------------------------------------------\n",
      "Training Data Statistics\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       1.00      0.99      0.99      3186\n",
      "       Toxic       0.87      0.98      0.92       314\n",
      "\n",
      "    accuracy                           0.98      3500\n",
      "   macro avg       0.93      0.98      0.96      3500\n",
      "weighted avg       0.99      0.98      0.98      3500\n",
      "\n",
      "--------------------------------------------------\n",
      "Overall Data Statistics\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.92      0.95      0.93      4563\n",
      "       Toxic       0.14      0.08      0.10       437\n",
      "\n",
      "    accuracy                           0.88      5000\n",
      "   macro avg       0.53      0.52      0.52      5000\n",
      "weighted avg       0.85      0.88      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score is \",round(SVC2.score(tf_idf_train,y_train),2))\n",
    "print(\"Testing score is \",round(SVC2.score(tf_idf_test,y_test),2))\n",
    "print(\"-\"*50)\n",
    "print(\"Training Data Statistics\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(y_train,SVC2.predict(tf_idf_train),target_names=[\"Non-Toxic\",\"Toxic\"]))\n",
    "print(\"-\"*50)\n",
    "print(\"Overall Data Statistics\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(Label,SVC2.predict(tf_idf_features),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285a708",
   "metadata": {},
   "source": [
    "# Conclusion \n",
    "---\n",
    "'Overall Data Statistics' results clearly shows - Toxic data predictibility high with  weights = {0:1.0, 1:85.0} compare to  'balanced' pre-defined. we continued to use 'balanced' as requested by assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9b8e3",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i> 11. Hyperparameter tuning\n",
    " - Import GridSearch and StratifiedKFold (because of class imbalance) <br>\n",
    " - Provide the parameter grid to choose for ‘C’ <br>\n",
    "    \n",
    "<i> 12. Use a balanced class weight while instantiating the Support Vector Classifier </i>\n",
    " - Find the parameters with the best recall in cross validation <br>\n",
    " - Choose ‘recall’ as the metric for scoring <br>\n",
    " - Choose stratified 5 fold cross validation scheme <br> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "827fc116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3278ab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'C': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2d35c649",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC3 = SVC(class_weight=\"balanced\",kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4710eae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GridSearchCV(SVC3, param_grid = params , cv=StratifiedKFold(5),scoring=['precision','recall', 'f1'], refit='recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ff0c9e",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i>13. Fit on the train set <br>\n",
    "14. What are the best parameters? <br>\n",
    " - Predict and evaluate using the best estimator <br>\n",
    " - Use best estimator from the grid search to make predictions on the test set <br>\n",
    " - What is the recall on the test set for the toxic comments? <br>\n",
    " - What is the f1_score? <br></i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bd0b769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=None, shuffle=False),\n",
       "             estimator=SVC(class_weight='balanced', kernel='linear'),\n",
       "             param_grid={'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]},\n",
       "             refit='recall', scoring=['precision', 'recall', 'f1'])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(tf_idf_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db7912a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=0.2, class_weight='balanced', kernel='linear')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "16834b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5923195084485406"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.best_score_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c400af90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is  0.96\n",
      "Testing score is  0.07\n",
      "--------------------------------------------------\n",
      "Training Data Statistics\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       1.00      0.97      0.98      3186\n",
      "       Toxic       0.77      0.96      0.86       314\n",
      "\n",
      "    accuracy                           0.97      3500\n",
      "   macro avg       0.88      0.97      0.92      3500\n",
      "weighted avg       0.98      0.97      0.97      3500\n",
      "\n",
      "--------------------------------------------------\n",
      "Overall Data Statistics\n",
      "--------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.91      0.95      0.93      4563\n",
      "       Toxic       0.11      0.07      0.08       437\n",
      "\n",
      "    accuracy                           0.87      5000\n",
      "   macro avg       0.51      0.51      0.51      5000\n",
      "weighted avg       0.84      0.87      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score is \",round(model.score(tf_idf_train,y_train),2))\n",
    "print(\"Testing score is \",round(model.score(tf_idf_test,y_test),2))\n",
    "print(\"-\"*50)\n",
    "print(\"Training Data Statistics\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(y_train,model.predict(tf_idf_train),target_names=[\"Non-Toxic\",\"Toxic\"]))\n",
    "print(\"-\"*50)\n",
    "print(\"Overall Data Statistics\")\n",
    "print(\"-\"*50)\n",
    "print(classification_report(Label,model.predict(tf_idf_features),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d3b2a",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "---\n",
    "Model is not generalized, training_accuracy > testing_accuracy (Overfitted model). Alternate approach using SMOTE can be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0323934d",
   "metadata": {},
   "source": [
    "### Task\n",
    "<i> 15. What are the most prominent terms in the toxic comments? <br>\n",
    " - Separate the comments from the test set that the model identified as toxic <br>\n",
    " - Make one large list of the terms <br>\n",
    " - Get the top 15 terms <br> </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "777c8c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(tf_idf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "8b5b7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6c91b7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"comments\"] = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "10ceb5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>quite accurate says debuted november 2004 coun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>harassing arbcom decision based lie said could...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>946</th>\n",
       "      <td>way english speaker going search spelling none...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>dear jeff g ツ blow fag</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>warangal fort deleted warangal fort contained ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments\n",
       "3912  quite accurate says debuted november 2004 coun...\n",
       "345   harassing arbcom decision based lie said could...\n",
       "946   way english speaker going search spelling none...\n",
       "1265                             dear jeff g ツ blow fag\n",
       "157   warangal fort deleted warangal fort contained ..."
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "95768d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"prediction\"] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "20c9f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"original\"] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ad8c978d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comments</th>\n",
       "      <th>prediction</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>gonna see able continue</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>please stop continue blank remove portions con...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2439</th>\n",
       "      <td>worse story invocation personal attacks reason...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>copyright problem removed prior content duplic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1946</th>\n",
       "      <td>imageadrianneweyjpg image deletion warning ima...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comments  prediction  original\n",
       "71                              gonna see able continue           0         0\n",
       "1561  please stop continue blank remove portions con...           0         0\n",
       "2439  worse story invocation personal attacks reason...           0         0\n",
       "1294  copyright problem removed prior content duplic...           0         0\n",
       "1946  imageadrianneweyjpg image deletion warning ima...           0         0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "7af1e67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_300_words = top_non_stopwords(new_df[\"comments\"][new_df[\"original\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7bb24bc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>suck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>mexicans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>shoot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>freak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word\n",
       "363      suck\n",
       "356  mexicans\n",
       "29      shoot\n",
       "29      freak\n",
       "20       like\n",
       "19       fuck\n",
       "18         go\n",
       "16      would\n",
       "12     people\n",
       "12       talk\n",
       "12       know\n",
       "11        gay\n",
       "11      think\n",
       "11        one"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_300_words.iloc[1:15,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3102e707",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_300_words = top_non_stopwords(new_df[\"comments\"][new_df[\"prediction\"]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "4d8f0333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>see</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>please</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>much</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>well</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>make</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>thanks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>edit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word\n",
       "30     see\n",
       "25   would\n",
       "17    talk\n",
       "16    like\n",
       "15  please\n",
       "15    also\n",
       "14    much\n",
       "14    well\n",
       "12   could\n",
       "11    make\n",
       "10  thanks\n",
       "10    know\n",
       "10    edit\n",
       "9   people"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_300_words.iloc[1:15,0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96c986d",
   "metadata": {},
   "source": [
    "### Approach2: SMOTE\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c7c0de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5f7610d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f7677833",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "46cc37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_features_smote,Label_smote  = smote.fit_resample(tf_idf_features,Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a437ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Sampling:\n",
      " 0    4563\n",
      "1     437\n",
      "Name: toxic, dtype: int64\n",
      "Post-Sampling:\n",
      " 0    4563\n",
      "1    4563\n",
      "Name: toxic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-Sampling:\\n\",Label.value_counts())\n",
    "print(\"Post-Sampling:\\n\",Label_smote.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ad2ad274",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = SVC(C=1.0, kernel='linear', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=- 1, decision_function_shape='ovr', break_ties=False, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "60db375b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC.fit(tf_idf_features_smote,Label_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "61ddf429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       1.00      0.95      0.97      4563\n",
      "       Toxic       0.95      1.00      0.97      4563\n",
      "\n",
      "    accuracy                           0.97      9126\n",
      "   macro avg       0.98      0.97      0.97      9126\n",
      "weighted avg       0.98      0.97      0.97      9126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Label_smote,SVC.predict(tf_idf_features_smote),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "aa5d1ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1,X_test1,y_train1,y_test1 = train_test_split(tf_idf_features_smote,Label_smote,test_size=0.30,random_state=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5d68c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train >> (6388, 4000) Test >> (2738, 4000)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train >>\", X_train1.shape, \"Test >>\", X_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "26a40e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVC.fit(X_train1,y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b665d09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score is  0.97\n",
      "Testing score is  0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"Training score is \",round(SVC.score(X_train1,y_train1),2))\n",
    "print(\"Testing score is \",round(SVC.score(X_test1,y_test1),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "767e8cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.99      0.95      0.97      3175\n",
      "       Toxic       0.95      0.99      0.97      3213\n",
      "\n",
      "    accuracy                           0.97      6388\n",
      "   macro avg       0.97      0.97      0.97      6388\n",
      "weighted avg       0.97      0.97      0.97      6388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train1,SVC.predict(X_train1),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "913958b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Non-Toxic       0.99      0.87      0.92      1388\n",
      "       Toxic       0.88      0.99      0.93      1350\n",
      "\n",
      "    accuracy                           0.93      2738\n",
      "   macro avg       0.93      0.93      0.93      2738\n",
      "weighted avg       0.93      0.93      0.93      2738\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test1,SVC.predict(X_test1),target_names=[\"Non-Toxic\",\"Toxic\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f5ef23",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "---\n",
    "Training score 0.97 > Testing score 0.93; but model performing much better in predicting Toxic. This is recommened approach for model building for imbalanced data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309b46c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e479069",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
